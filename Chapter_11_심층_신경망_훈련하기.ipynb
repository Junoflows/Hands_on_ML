{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XzGAbcH2YlY-"
      ],
      "authorship_tag": "ABX9TyMNHhcAxKoPPag5YYVrrYhL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junoflows/Hands_on_ML/blob/main/Chapter_11_%EC%8B%AC%EC%B8%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%9B%88%EB%A0%A8%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 설정"
      ],
      "metadata": {
        "id": "XzGAbcH2YlY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "YAL7haM7YiVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 11 심층 신경망 훈련하기"
      ],
      "metadata": {
        "id": "dgkcj278FwRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "심층 신경망\n",
        "+ 수백 개의 뉴런을 구성된 10개 이상의 층을 사용하는 신경망"
      ],
      "metadata": {
        "id": "r3xkGGRYF-hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "심층 신경망 훈련 중 발생하는 문제\n",
        "+ 그레디언트 소실 / 폭주 문제\n",
        "+ 훈련 데이터 부족 또는 너무 비싼 레이블 작업\n",
        "+ 극단적으로 느린 훈련과정\n",
        "+ 과대적합 - 특히 훈련 샘플이 충분하지 않거나 잡음이 많은 경우"
      ],
      "metadata": {
        "id": "xEgfdrPEGJa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 장에서는 위 문제들의 해결책 제시한다."
      ],
      "metadata": {
        "id": "Wrrly9XvGnVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.1 그레디언트 소실과 폭주 문제"
      ],
      "metadata": {
        "id": "QA1aHEqIGsBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "역전파 알고리즘\n",
        "+ 출력층에서 입력층으로 오차 그레디언트를 전파\n",
        "+ 하위층으로 갈수록 그레디언트 소실/폭주 문제가 발생함"
      ],
      "metadata": {
        "id": "bXHslQDAH5GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원인 : 활성화 함수와 가중치 초기화를 위해 아래 조합을 선택하였기 때문\n",
        "+ 활성화 함수 : 시그모이드 함수 사용\n",
        "+ 가중치 초기화 : 표준정규분포 활용\n",
        "+ 위 방식을 사용했을 때 각 층에서 출력의 분산이 입력의 분산보다 더 크다는 것을 밝혀짐"
      ],
      "metadata": {
        "id": "WzxxRZhDI26S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-01.png' width = 50%> <br/>\n",
        "+ 입력이 커지면 기울기가 0에 수렴하므로 하위 증으로 갈수록 그레디언트가 전파되지 않는다."
      ],
      "metadata": {
        "id": "9laRyl5AJc8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.1.1 글로럿, He 초기화"
      ],
      "metadata": {
        "id": "IAbl1igXJmAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 글로럿 초기화\n",
        "+ 각 층의 출력에 대한 분산과 입력에 대한 분산과 같아야 함\n",
        "+ 역방향에서 층을 통과하기 전과 후의 그레디언트 분산이 같아야 함\n",
        "+ 각 층의 연결 가중치를 아래 방식대로 무작위로 초기화하는 대안을 제안"
      ],
      "metadata": {
        "id": "9iRR-AB5K5uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "팬-인/팬-아웃\n",
        "+ $fan_{in}$ : 층에 들어오는 입력 수\n",
        "+ $fan_{out}$ : 층에서 나가는 출력 수\n",
        "+ $ fan_{avg} = \\frac{fan_{in} + fan_{out} }{2} $\n"
      ],
      "metadata": {
        "id": "12M3lRrfOYJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "글로럿 초기화 (시그모이드 활성화 함수를 사용할 때)\n",
        "+ 평균이 0 이고 분산 $σ^2 = \\frac{1}{fan_{avg}}$ 인 정규분포로 초기화\n",
        "+ $r = \\sqrt{\\frac{3}{fan_{avg}}}$ 이고 $-r$과 $r$ 사이의 균등분포로 초기화"
      ],
      "metadata": {
        "id": "b-RmYztPPy8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "르쿤(LeCun) 초기화\n",
        "+ 글로럿 초기화에서 $fan_{avg}$ 를 $fan_{in}$ 으로 대체"
      ],
      "metadata": {
        "id": "K1sHdW3hRFVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### He 초기화\n",
        "+ ReLU 계열의 활성화 함수를 사용했을 때의 사용하는 초기화 전략\n",
        "+ $σ^2 = \\frac{2}{fan_{in}}$ (정규분포 활용 초기화)\n",
        "\n",
        "+ $r = \\sqrt{3σ^2}$ (균등분포 활용 초기화)"
      ],
      "metadata": {
        "id": "Nl5wUWdVRFQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 활성화 함수와 초기화 방식"
      ],
      "metadata": {
        "id": "1YOnzaRGThTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 초기화 전략      | 활성화 함수                                       | 정규분포 초기화 |\n",
        "|------------------|--------------------------------------------------|----------------|\n",
        "| Glorot 초기화    | 활성화 함수 없는 경우, 하이퍼볼릭 탄젠트, 로지스틱, 소프트맥스 | glorot_normal  |\n",
        "| He 초기화        | ReLU 함수와 그 변종들                             | he_normal      |\n",
        "| LeCun 초기화     | SELU                                             | lecun_normal   |\n"
      ],
      "metadata": {
        "id": "8u2VI3LLTyOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 케라스는 기본적으로 균등분포의 글로럿 초기화를 사용\n",
        "+ 정규분포를 이용한 He 초기화를 사용하고자 하는 경우"
      ],
      "metadata": {
        "id": "NwbQbEE3T9-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8xqE1FrPOn7",
        "outputId": "59cf12ba-ade7-4010-b316-9011153ede12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7d91d1c3a950>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $fan_{in}$ 대신 $fan_{out}$  기반의 균등분포 He 초기화를 사용하고자 할 경우"
      ],
      "metadata": {
        "id": "F1-8hCDdU34P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VarianceScaling 클래스 활용\n",
        "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX2--Vm7Ut6z",
        "outputId": "82fffb23-3eec-4035-a3e1-90e0afd48b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7d914adb46a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.1.2 수렴하지 않는 활성화 함수"
      ],
      "metadata": {
        "id": "3pXMYJ6vVTpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 심층신경망의 층에서 사용되는 활성화 함수는 시그모이드 함수보다 아래 함수들이 보다 좋은 성능을 발휘함\n",
        "+ ReLU, LeakyReLU, RReLU, PReLU, ELU, SELU"
      ],
      "metadata": {
        "id": "kMIyPqCMVjjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ReLU\n",
        "+ 특정 양수 값에 수렴하지 않고 계산도 빠름\n",
        "+ $ReLU(z) = max(0, z)$\n",
        "+ __죽은 ReLU__ 로 알려진 문제가 존재\n",
        "  + 입력 가중치 합이 음수가 되면 뉴런이 죽게 되어 경사하강법이 제대로 작동하지 않음"
      ],
      "metadata": {
        "id": "NBJsZCknWbsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-02a.png' width = 50%>"
      ],
      "metadata": {
        "id": "JNHSPZIIW96M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LeakyReLU\n",
        "+ $LeakyReLU(z) = max(az, z)$\n",
        "  + $a$ : 새는(leaky) 정도를 결정하는 하이퍼파라미터\n",
        "+ ReLU 보다 좋은 성능 발휘\n",
        "  + 일반적으로 $a$는 0.01이나 0.2를 많이 사용하고 기본값은 0.01"
      ],
      "metadata": {
        "id": "ItByFCniXMl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-03.png' width = 50%>"
      ],
      "metadata": {
        "id": "qxvCGyFVYBgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RReLU\n",
        "+ $a$를 주어진 범위에서 무작위로 선택하는 LeakyReLU\n",
        "+ 잘 작동하며 과대적합을 줄이는 규제역할도 수"
      ],
      "metadata": {
        "id": "UelnxdJ5YKIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PReLU\n",
        "+ 역전파 과정에서 $a$값도 자동 조정됨(하이퍼파라미터가 아님)\n",
        "+ 대규모 데이터셋에서 ReLU보다 성능이 앞섰지만 소규모 데이터셋에서는 과대적합 위험성이 존재함"
      ],
      "metadata": {
        "id": "-W9jD_ngYYBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ELU\n",
        "+ ReLU 계열 활성화함수들보다 훈련 시간이 줄고 성능이 더 높음\n",
        "+ $ \\text{ELU}_\\alpha(z) = \\begin{cases}\n",
        "  \\alpha (\\exp(z) - 1) & \\text{if } z < 0 \\\\\n",
        "  z & \\text{if } z \\geq 0\n",
        "\\end{cases} $\n"
      ],
      "metadata": {
        "id": "tXldjPCyY6th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-04.png' width = 50%>"
      ],
      "metadata": {
        "id": "0PDoikzNZulI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELU 함수의 장단점\n",
        "+ 수렴 속도 빠름\n",
        "+ 지수함수가 사용되어 계산이 느림\n",
        "+ 테스트 시 ReLU 를 사용한 신경망보다 느림"
      ],
      "metadata": {
        "id": "pUgHDuBNZ0at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SELU\n",
        "+ 스케일이 조정된 ELU 함수의 변종\n",
        "+ 아래 조건에서 뛰어난 성능을 보임\n",
        "  + 입력 특성이 표준화되어야 함\n",
        "  + 모든 은닉층에서 르쿤 정규분포 초기화 사용\n",
        "  + 일렬로 쌓은 층으로 구성되어야 함\n",
        "  + 모든 층이 완전연결층이어야 함"
      ],
      "metadata": {
        "id": "A8xJRgbvaE6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GELU"
      ],
      "metadata": {
        "id": "ZIBJGNGibK8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $ \\text{GELU}(x) = x \\cdot \\Phi(x)$ <br/>\n",
        "+ $ \\Phi(x) = \\frac{1}{2} \\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right] $\n",
        "\n"
      ],
      "metadata": {
        "id": "6IyhZQOUbP8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://iq.opengenus.org/content/images/2021/12/gelufunction.png' width = 50%>"
      ],
      "metadata": {
        "id": "rVK1SdHEb4-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 입력 데이터의 가우시안 분포를 가정\n",
        "+ 자연어 처리 분야에서 널리 사용"
      ],
      "metadata": {
        "id": "bbdlFaGAbckc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 심층신경망의 은닉층에 대한 활성화 함수 선택 가이드라인\n",
        "+ 일반적인 우선순위 : SELU > ELU > LeakyReLU 기반 > ReLU > 시그모이드\n",
        "+ 신경망이 Self-normalizing 하지 않은 경우 : SeLU 보다 ELU 선호\n",
        "+ 시간과 컴퓨팅 파워가 충분하다면 교차검증을 통해 여러 활성화 함수 성능을 비교\n",
        "+ 실행속도가 중요한 경우: LeakyReLU\n",
        "+ 과대적합 발생하는 경우: RReLU\n",
        "+ 훈련세트가 매우 큰 경우: PReLU\n",
        "+ 훈련속도가 중요한 경우: ReLU"
      ],
      "metadata": {
        "id": "VtV7U43edeGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 예시\n",
        "+ RReLU 를 제외한 활성화함수는 쉽게 구현가능"
      ],
      "metadata": {
        "id": "3hBuKRl2emB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dfk8wCkpVVhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d590fc38-3c9a-4a15-d3d2-c8a601342046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " p_re_lu (PReLU)             (None, 300)               300       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266910 (1.02 MB)\n",
            "Trainable params: 266910 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.1.3 배치정규화"
      ],
      "metadata": {
        "id": "hSdayK3tVJbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ ELU(또는 다른 ReLU 변종) + He 초기화 를 사용하면 훈련 초기 그레디언트 소실/폭주 문제 해결\n",
        "+ 훈련 중 동일 문제가 재발하지 않을 것이란 보장이 없음\n",
        "+ 해결 방안으로 배치정규화 기법을 제안"
      ],
      "metadata": {
        "id": "ahFD_yt7VzWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 배치정규화 알고리즘"
      ],
      "metadata": {
        "id": "8Be5biQOaq2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $\\mu_B = \\frac{1}{m_B} \\sum_{i=1}^{m_B} x^{(i)}$\n",
        "\n",
        "2. $\\sigma_B^2 = \\frac{1}{m_B} \\sum_{i=1}^{m_B} (x^{(i)} - \\mu_B)^2$\n",
        "\n",
        "3. $\\hat{x}^{(i)} = \\frac{x^{(i)} - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$ ($\\epsilon$ 은 일반적으로 $10^{-5}$)\n",
        "\n",
        "4. $z^{(i)} = \\gamma \\odot \\hat{x}^{(i)} + \\beta$ ($\\beta$ : 층의 출력 이동 파라미터)\n"
      ],
      "metadata": {
        "id": "oDEZ4ciIZucD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 훈련 시 입력을 정규화하고 스케일을 조정하고 이동시킴"
      ],
      "metadata": {
        "id": "qA49o9niLT_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 배치 정규화의 효과\n",
        "+ 드롭아웃 같은 규제 역할을 하여 다른 규제 기법의 필요성을 줄여줌\n",
        "+ sigmoid 나 tanh 활성화 함수 사용 가능\n"
      ],
      "metadata": {
        "id": "9gZF92aaMbVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 케라스로 배치정규화 구현\n",
        "+ 은닉층의 활성화 함수 이전이나 이후에 BatchNormalization 층 추가"
      ],
      "metadata": {
        "id": "L54DjTlrSfBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 활성화 함수 이후에 정규화 층 추가\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "nUMJywqQVKSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 활성화 함수 이전에 정규화 층 추가\n",
        "# 활성화 함수를 정규화 층 뒤에 별도의 층으로 추가함\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(100, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "6nndKuD9Sn1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 배치정규화 활용\n",
        "+ 보통 모든 층 뒤에 배치정규화가 있다고 가정\n",
        "+ 따라서 신경망 그림에 종종 생략됨"
      ],
      "metadata": {
        "id": "OoM6MyelaHqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 전이학습"
      ],
      "metadata": {
        "id": "6DboVfJ8dY7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 전이학습\n",
        "+ 비슷한 기능을 가진 사전훈련된 모델의 일부 층을 재사용하는 방법\n",
        "+ 훈련속도를 크게 높이고 필요한 훈련 데이터의 양도 크게 줄여줌\n",
        "+ 하위층에서 저수준 특성이 학습되기 때문에 비슷한 원본모델의 하위 은닉층이 훨씬 유용함"
      ],
      "metadata": {
        "id": "B_sjRorDVkuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-05.png' width = 50%>"
      ],
      "metadata": {
        "id": "xbNToZAUV0oK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전이학습 단계\n",
        "1. 재사용 층을 모두 동결하고 훈련\n",
        "2. 성능 평가 후 1~2개 은닉층의 동결을 해제하고 가중치 조정 - 학습률을 줄이는게 가중치 조정에 효과적\n",
        "3. 성능이 좋아지지 않거나 데이터가 적을 경우 상위 은닉층 제거 후 남은 은닉층 동결하고 다시 훈련\n",
        "4. 훈련 데이터가 많을 경우 더 많은 은닉층 추가 가능\n",
        "5. 위 과정 반복"
      ],
      "metadata": {
        "id": "ndPnMVAtV_Vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.2.1 케라스를 사용한 전이 학습"
      ],
      "metadata": {
        "id": "elSRlCOuW3Kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가정 : model_A 주어짐\n",
        "  + 샌들과 셔츠를 제외한 8개의 클래스만 담겨있는 패션 MNIST\n",
        "  + 90% 이상의 정확도 성능을 갖는 8개의 클래스 분류 학습 모델\n",
        "\n",
        "목표 : 셔츠와 샌들을 분류하는 이진분류기 model_B 훈련"
      ],
      "metadata": {
        "id": "h4eO3kz8X0D9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "방법 : 전이학습을 이용한 model_B_on_A 훈련"
      ],
      "metadata": {
        "id": "a2JiDWE0YJgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ model_A 생성"
      ],
      "metadata": {
        "id": "3DVCxtUyaD8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9oNlWYCZC70",
        "outputId": "6a3c0126-567d-45b9-ee0b-c061f6db46be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ],
      "metadata": {
        "id": "2M9WcMIkdDti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.Sequential()\n",
        "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "at1UcWFLY6RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "V2JEiw3hY7Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                    validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMxaWQZvY8ES",
        "outputId": "d3dc1a1c-eb29-47db-83c2-a3f58a5564c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1375/1375 [==============================] - 13s 8ms/step - loss: 0.5734 - accuracy: 0.8183 - val_loss: 0.3859 - val_accuracy: 0.8632\n",
            "Epoch 2/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.3559 - accuracy: 0.8781 - val_loss: 0.3243 - val_accuracy: 0.8871\n",
            "Epoch 3/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.3197 - accuracy: 0.8904 - val_loss: 0.2997 - val_accuracy: 0.8961\n",
            "Epoch 4/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.3001 - accuracy: 0.8972 - val_loss: 0.2867 - val_accuracy: 0.9031\n",
            "Epoch 5/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2870 - accuracy: 0.9021 - val_loss: 0.2763 - val_accuracy: 0.9061\n",
            "Epoch 6/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2772 - accuracy: 0.9059 - val_loss: 0.2724 - val_accuracy: 0.9066\n",
            "Epoch 7/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2689 - accuracy: 0.9094 - val_loss: 0.2678 - val_accuracy: 0.9078\n",
            "Epoch 8/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2622 - accuracy: 0.9109 - val_loss: 0.2596 - val_accuracy: 0.9126\n",
            "Epoch 9/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2566 - accuracy: 0.9125 - val_loss: 0.2566 - val_accuracy: 0.9126\n",
            "Epoch 10/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2518 - accuracy: 0.9137 - val_loss: 0.2533 - val_accuracy: 0.9118\n",
            "Epoch 11/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2474 - accuracy: 0.9160 - val_loss: 0.2502 - val_accuracy: 0.9136\n",
            "Epoch 12/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2433 - accuracy: 0.9167 - val_loss: 0.2501 - val_accuracy: 0.9121\n",
            "Epoch 13/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2399 - accuracy: 0.9185 - val_loss: 0.2452 - val_accuracy: 0.9153\n",
            "Epoch 14/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2364 - accuracy: 0.9186 - val_loss: 0.2443 - val_accuracy: 0.9163\n",
            "Epoch 15/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2335 - accuracy: 0.9199 - val_loss: 0.2464 - val_accuracy: 0.9155\n",
            "Epoch 16/20\n",
            "1375/1375 [==============================] - 6s 5ms/step - loss: 0.2304 - accuracy: 0.9216 - val_loss: 0.2431 - val_accuracy: 0.9173\n",
            "Epoch 17/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2279 - accuracy: 0.9227 - val_loss: 0.2454 - val_accuracy: 0.9131\n",
            "Epoch 18/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2250 - accuracy: 0.9231 - val_loss: 0.2468 - val_accuracy: 0.9123\n",
            "Epoch 19/20\n",
            "1375/1375 [==============================] - 8s 6ms/step - loss: 0.2226 - accuracy: 0.9240 - val_loss: 0.2369 - val_accuracy: 0.9160\n",
            "Epoch 20/20\n",
            "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2205 - accuracy: 0.9251 - val_loss: 0.2374 - val_accuracy: 0.9150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.h5\")"
      ],
      "metadata": {
        "id": "h1PW3uWnY9c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 전이학습하지 않는 model_B 생성"
      ],
      "metadata": {
        "id": "oJMdYZkTaFtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_B = keras.models.Sequential()\n",
        "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "2taHoT-xaLyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fZk-MOAJaMn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YuDo6esaNJZ",
        "outputId": "cc074d14-d58f-493c-ab92-c4e8933a0e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 1s 51ms/step - loss: 0.6935 - accuracy: 0.5750 - val_loss: 0.6110 - val_accuracy: 0.6410\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5670 - accuracy: 0.7000 - val_loss: 0.5068 - val_accuracy: 0.7667\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4673 - accuracy: 0.7950 - val_loss: 0.4333 - val_accuracy: 0.8448\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3965 - accuracy: 0.8550 - val_loss: 0.3774 - val_accuracy: 0.8925\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3420 - accuracy: 0.9200 - val_loss: 0.3318 - val_accuracy: 0.9280\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2964 - accuracy: 0.9500 - val_loss: 0.2970 - val_accuracy: 0.9361\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2633 - accuracy: 0.9700 - val_loss: 0.2697 - val_accuracy: 0.9462\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2358 - accuracy: 0.9700 - val_loss: 0.2468 - val_accuracy: 0.9554\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2137 - accuracy: 0.9800 - val_loss: 0.2272 - val_accuracy: 0.9604\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1946 - accuracy: 0.9800 - val_loss: 0.2108 - val_accuracy: 0.9655\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1786 - accuracy: 0.9800 - val_loss: 0.1966 - val_accuracy: 0.9675\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1646 - accuracy: 0.9800 - val_loss: 0.1848 - val_accuracy: 0.9696\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1528 - accuracy: 0.9850 - val_loss: 0.1747 - val_accuracy: 0.9726\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1429 - accuracy: 0.9850 - val_loss: 0.1656 - val_accuracy: 0.9726\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1339 - accuracy: 0.9850 - val_loss: 0.1571 - val_accuracy: 0.9767\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1256 - accuracy: 0.9850 - val_loss: 0.1502 - val_accuracy: 0.9767\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1188 - accuracy: 0.9850 - val_loss: 0.1441 - val_accuracy: 0.9767\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1128 - accuracy: 0.9850 - val_loss: 0.1385 - val_accuracy: 0.9777\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1071 - accuracy: 0.9850 - val_loss: 0.1331 - val_accuracy: 0.9787\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1019 - accuracy: 0.9850 - val_loss: 0.1289 - val_accuracy: 0.9777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 전이학습 이용하는 model_B_on_A 생성"
      ],
      "metadata": {
        "id": "i2vJwLEbaQa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "SJIs_SFkZSN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ model_B_on_A와 model_A는 층을 공유하기 때문에 하나를 훈련하면 두 모델이 업데이트됨\n",
        "+ 따라서 model_A를 클론한 것을 사용해 model_B_on_A를 만들어야 함"
      ],
      "metadata": {
        "id": "K2dy6dzTaXGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())\n",
        "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "fQqF_K9saYAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LmhhgCbYajqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
        "                           validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFCECCxaakBU",
        "outputId": "428594a7-0d3a-40f1-c1a5-065d7c1651e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "7/7 [==============================] - 1s 63ms/step - loss: 0.4382 - accuracy: 0.7800 - val_loss: 0.4661 - val_accuracy: 0.7688\n",
            "Epoch 2/4\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.4160 - accuracy: 0.7800 - val_loss: 0.4425 - val_accuracy: 0.7819\n",
            "Epoch 3/4\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3935 - accuracy: 0.7950 - val_loss: 0.4219 - val_accuracy: 0.7941\n",
            "Epoch 4/4\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3738 - accuracy: 0.7950 - val_loss: 0.4027 - val_accuracy: 0.8012\n",
            "Epoch 1/16\n",
            "7/7 [==============================] - 1s 64ms/step - loss: 0.3063 - accuracy: 0.8450 - val_loss: 0.2774 - val_accuracy: 0.8945\n",
            "Epoch 2/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2091 - accuracy: 0.9250 - val_loss: 0.2113 - val_accuracy: 0.9300\n",
            "Epoch 3/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1565 - accuracy: 0.9700 - val_loss: 0.1735 - val_accuracy: 0.9533\n",
            "Epoch 4/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1265 - accuracy: 0.9850 - val_loss: 0.1479 - val_accuracy: 0.9665\n",
            "Epoch 5/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1061 - accuracy: 0.9900 - val_loss: 0.1303 - val_accuracy: 0.9686\n",
            "Epoch 6/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0914 - accuracy: 0.9900 - val_loss: 0.1165 - val_accuracy: 0.9726\n",
            "Epoch 7/16\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0801 - accuracy: 0.9950 - val_loss: 0.1065 - val_accuracy: 0.9746\n",
            "Epoch 8/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9797\n",
            "Epoch 9/16\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9817\n",
            "Epoch 10/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9838\n",
            "Epoch 11/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9848\n",
            "Epoch 12/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9848\n",
            "Epoch 13/16\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9858\n",
            "Epoch 14/16\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9858\n",
            "Epoch 15/16\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9858\n",
            "Epoch 16/16\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_B 와 model_B_on_A 성능 비교"
      ],
      "metadata": {
        "id": "QvVuMNp6aoAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XLvIrfBalt1",
        "outputId": "85c3de0a-7b82-422f-e33d-853519c09643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1244 - accuracy: 0.9840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1243593692779541, 0.984000027179718]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bu2X5FSasGc",
        "outputId": "f9682961-ca41-4cdf-a965-155b30a91bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05782657116651535, 0.9900000095367432]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(100 - 98.40) / (100 - 99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxVqoKGzatcg",
        "outputId": "2dcd5d15-c65f-4ceb-d8b7-c90f8aacc771"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5999999999999943"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.2.2 비지도 전이학습"
      ],
      "metadata": {
        "id": "W7xFRknsb7D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 레이블된 훈련 데이터가 없을 경우\n",
        "+ 레이블이 없는 훈련 데이터를 오토인코더나 GAN 등을 이용해 레이블 지정 후 하위층을 재사용"
      ],
      "metadata": {
        "id": "ubxtQSYS_OM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://velog.velcdn.com/images/tedlim23/post/46517f98-e66a-4ccb-b44a-66b1ad08e4df/Untitled%201.png' width = 50%>"
      ],
      "metadata": {
        "id": "ci7FhpTGA4xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.2.3 보조 작업에서 전이학습"
      ],
      "metadata": {
        "id": "ZX5df8jjBDNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 레이블된 훈련 데이터가 적을 경우\n",
        "+ 레이블된 데이터를 얻거나 생성할 수 있는 보조 작업에서 첫 번째 신경망을 훈련하고 재사용"
      ],
      "metadata": {
        "id": "b0HdrMliBXJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 : 얼굴 인식 시스템\n",
        "+ 개인별 이미지가 많지 않은 경우\n",
        "+ 인터넷에서 무작위로 인물 이미지 수집\n",
        "+ 두 개의 다른이미지를 분류하는 신경망 훈련\n",
        "+ 학습된 모델의 하위층을 재사용\n",
        "+ 적은 양의 레이블된 훈련 데이터를 이용하여 얼굴 인식 분류기 학습 가능"
      ],
      "metadata": {
        "id": "WQ4c0nwmBtVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.3 고속 옵티마이저"
      ],
      "metadata": {
        "id": "Zh2d2Q3sB_Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 속도를 크게 높일 수 있는 옵티마이저 소개"
      ],
      "metadata": {
        "id": "5QFwQ2smDB9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "경사 하강법 알고리즘\n",
        "+ $\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} J(\\theta)$"
      ],
      "metadata": {
        "id": "eIHyIToBD79T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.1 모멘텀 최적화"
      ],
      "metadata": {
        "id": "0fvMlEjjDIn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $m \\leftarrow \\beta m - \\eta \\nabla_{\\theta} J(\\theta)$\n",
        "2. $\\theta \\leftarrow \\theta + m$\n"
      ],
      "metadata": {
        "id": "ImUJwgm7DOHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이전 그레디언트가 이후 그레디언트에 영향을 줌\n",
        "+ 일반 경사하강법보다 빠르게 전역 최소점에 도달"
      ],
      "metadata": {
        "id": "GMylRUkmEjg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "iqsq6Dihb9Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5b1990-a6fa-4d2c-a721-79462f48ff91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.2 Nesterov 가속 경사(NAG)"
      ],
      "metadata": {
        "id": "xOmlvLRlGlTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $m \\leftarrow \\beta m - \\eta \\nabla_{\\theta} J(\\theta + \\beta m)$\n",
        "2. $\\theta \\leftarrow \\theta + m$\n"
      ],
      "metadata": {
        "id": "7MT9GlCAHBxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 모멘텀 가속화 기법을 수정\n",
        "+ 기존 모멘텀 최적화보다 훈련속도가 빠름"
      ],
      "metadata": {
        "id": "SAJhDMOTHc-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-06.png' width = 50%>"
      ],
      "metadata": {
        "id": "oFRHfPJeHsrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "BKYJi9hxH46L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.3 AdaGrad"
      ],
      "metadata": {
        "id": "2ElEEi7D186K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $s \\leftarrow s + \\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta)$\n",
        "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_{\\theta}J(\\theta) \\oslash \\sqrt{s + \\epsilon}$\n"
      ],
      "metadata": {
        "id": "fr-JUk1s2Wc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 전역 최적점 방향으로 더 곧장 가도록 도와줌\n",
        "+ 간단한 2차방정식 문제에 대해서 잘 작동함\n",
        "+ 신경망 훈련 시 너무 일찍 멈추는 경향이 있음"
      ],
      "metadata": {
        "id": "pjLR0eyX2jCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-07.png' width = 50%>"
      ],
      "metadata": {
        "id": "wgiqN2Gc235x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adagrad(lr=0.001)"
      ],
      "metadata": {
        "id": "bOOs09GYGp95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d72571-a012-405a-cf4d-0e35e743c91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.4 RMSProp"
      ],
      "metadata": {
        "id": "e0JlLmyC2-Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $s \\leftarrow \\beta s + (1 - \\beta) \\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta)$\n",
        "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_{\\theta}J(\\theta) \\oslash (\\sqrt{s + \\epsilon})$\n"
      ],
      "metadata": {
        "id": "Dnni35fH4xXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ AdaGrad의 이른 종료 문제점을 해결한 기법\n",
        "+ 가장 최근 반복의 그레디언트만 누적하여 해결 (지수 감소 평균)"
      ],
      "metadata": {
        "id": "h_3MU2J33n7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3.5 Adam과 Nadam 최적화"
      ],
      "metadata": {
        "id": "esSJcn2X5K-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $m \\leftarrow \\beta_1 m - (1 - \\beta_1) \\nabla_{\\theta}J(\\theta)$\n",
        "2. $s \\leftarrow \\beta_2 s + (1 - \\beta_2) \\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta)$\n",
        "3. $\\hat{m} \\leftarrow \\frac{m}{1 - \\beta_1^t}$\n",
        "4. $\\hat{s} \\leftarrow \\frac{s}{1 - \\beta_2^t}$\n",
        "5. $\\theta \\leftarrow \\theta + \\eta \\hat{m} \\oslash (\\sqrt{\\hat{s} + \\epsilon})$\n"
      ],
      "metadata": {
        "id": "ZvLkZByn59ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 모멘텀 최적화와 RMSProp 아이디어를 활용\n",
        "+ 3,4 단계에서 m, s 를 0으로 치우치지 않도록 증폭하는 효과"
      ],
      "metadata": {
        "id": "lnwMbWcX6ECv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "3GJQZVY52_5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AdaMax"
      ],
      "metadata": {
        "id": "LUyTXzfK8-r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. $m \\leftarrow \\beta_1 m - (1 - \\beta_1) \\nabla_{\\theta}J(\\theta)$\n",
        "2. $s \\leftarrow \\max(\\beta_2 s, \\nabla_{\\theta}J(\\theta))$\n",
        "3. $\\hat{m} \\leftarrow \\frac{m}{1 - \\beta_1^t}$\n",
        "4. $\\theta \\leftarrow \\theta + \\eta \\hat{m} \\oslash (\\sqrt{\\hat{s} + \\epsilon})$\n"
      ],
      "metadata": {
        "id": "PUm0wspE9Fjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Adam 알고리즘 개선\n",
        "+ 경우에 따라 Adam 성능이 더 좋음"
      ],
      "metadata": {
        "id": "cJjm_4od9kUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "ykcSgWDX9q9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nadam"
      ],
      "metadata": {
        "id": "bCNv_mU79o4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Adam + Nesterov\n",
        "+ 일반적으로 Adam 보다 성능 좋지만 경우에 따라 RMSProp이 더 좋기도 함\n"
      ],
      "metadata": {
        "id": "TEqSFAn59wB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "mZahXoCB84w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 옵티마이저 정리"
      ],
      "metadata": {
        "id": "zUOxuSE0-NqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 선택한 옵티마이저의 성능이 만족스럽지 않을 경우 기본 Nesterov 가속 경사 사용 추천\n",
        "+ 새로운 기법 활용에 관심 가질 것"
      ],
      "metadata": {
        "id": "w83Ig96I-O_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 클래스                             | 수렴 속도 | 수렴 품질           |\n",
        "|------------------------------------|-----------|---------------------|\n",
        "| SGD                                | *         | ***                 |\n",
        "| SGD(momentum=...)                  | **        | ***                 |\n",
        "| SGD(momentum=..., nesterov=...)    | **        | ***                 |\n",
        "| Adagrad                            | ***       | * (너무 일찍 멈춤)   |\n",
        "| RMSProp                            | ***       | ** 또는 ***         |\n",
        "| Adam                               | ***       | ** 또는 ***         |\n",
        "| Nadam                              | ***       | ** 또는 ***         |\n",
        "| AdaMax                             | ***       | ** 또는 ***         |\n"
      ],
      "metadata": {
        "id": "FCfumZGN-3EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.4 규제를 사용해 과대적합 피하기"
      ],
      "metadata": {
        "id": "IWO68RE-C3Ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 심층 신경망에 사용되는 수백만 개의 파라미터에 의해 과대적합이 발생하기 쉬움\n",
        "+ 다양한 규제를 사용해 과대적합을 해결"
      ],
      "metadata": {
        "id": "ErhEamRYDAcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지의 살펴본 규제 기법\n",
        "  + EarlyStopping, 배치정규화"
      ],
      "metadata": {
        "id": "wn29H7SIDSoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $l_1$, $l_2$ 규제"
      ],
      "metadata": {
        "id": "etN2QHdnDWe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $l_1$ 규제\n",
        "+ $ L = L_{\\text{original}} + \\lambda \\sum_{i=1}^{n} |w_i|$\n",
        "+ 덜 중요한 특성의 가중치를 0으로 만들어서 학습에서 제외시키는 효과 (특성 선택)"
      ],
      "metadata": {
        "id": "_kQvhN17FHeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $l_2$ 규제\n",
        "+ $L = L_{\\text{original}} + \\lambda \\sum_{i=1}^{n} w_i^2$\n",
        "+ 가중치의 크기를 줄이되 0으로 만들지는 않음\n",
        "+ 가중치의 큰 값에 대해 더 큰 패널티를 부여"
      ],
      "metadata": {
        "id": "slYiyRCiF7_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))"
      ],
      "metadata": {
        "id": "PKFrcwWc96N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.4.2 드롭 아웃"
      ],
      "metadata": {
        "id": "7CPC7S6RG6NM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망에서 가장 인기 있는 규제기법\n",
        "+ 일반적으로 매우 잘 작동함"
      ],
      "metadata": {
        "id": "QFcP3mYTG9r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 아이디어"
      ],
      "metadata": {
        "id": "AUXEaPIGHBVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://formal.hknu.ac.kr/handson-ml2/slides/images/ch11/homl11-09.png' width = 50%>"
      ],
      "metadata": {
        "id": "4lBkzVsMHEAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 매 훈련에서 각 뉴런을 특정 확률로 훈련에서 제외시킴\n",
        "+ 드롭아웃 비율을 올려야 하는 경우\n",
        "  + 과대적합 발생하는 경우\n",
        "  + 층에 많은 뉴런이 포함될 때\n",
        "\n",
        "+ 일반적으로 출력층을 제외한 최상위 3개 층에 대해 드롭아웃 적용"
      ],
      "metadata": {
        "id": "45coYRVZHIJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])"
      ],
      "metadata": {
        "id": "WadZ1NzbG7Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.4.3 몬테 카를로 드롭아웃"
      ],
      "metadata": {
        "id": "GG3lSC_JHxct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 훈련된 드롭아웃 모델을 재훈련하지 않으면서 성능을 향상시키는 기법\n",
        "+ 모델의 불확실성을 더 잘 측정할 수 있음"
      ],
      "metadata": {
        "id": "6oODiA13H6nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.4.4 맥스-노름(max-norm) 규제"
      ],
      "metadata": {
        "id": "avBL2yE9I5dD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 각 뉴런에 대해 입력 가중치 $w$가 $||w|| \\le r$ 이 되도록 제한\n",
        "+ 14장 CNN 층에서 max-norm 을 적용하려면 axis 값을 적절히 지정해야함 (axis = [0,1,2])"
      ],
      "metadata": {
        "id": "Rz7QEbzUJAG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ],
      "metadata": {
        "id": "wRWKM6zCI9SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.5 요약 및 실용적인 가이드 라인"
      ],
      "metadata": {
        "id": "mfAtmaSoJ-BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 기본 DNN 설정\n",
        "| 하이퍼파라미터      | 기본값                             |\n",
        "|-------------------|----------------------------------|\n",
        "| 커널초기화          | He 초기화                          |\n",
        "| 활성화 함수         | ELU                               |\n",
        "| 정규화              | 깊은 신경망일 경우에만 배치정규화 사용     |\n",
        "| 규제                | 조기종료, 경우에 따라 $ l_2$ 규제 추가 |\n",
        "| 옵티마이저           | 모멘텀 최적화, RMSProp, Nadam 중 하나    |\n",
        "| 학습률 스케줄        | 1사이클                            |\n",
        "\n"
      ],
      "metadata": {
        "id": "AEDrPfs6ZbZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 자기정규화를 위한 DNN 설정\n",
        "| 하이퍼파라미터      | 기본값                                         |\n",
        "|-------------------|-----------------------------------------------|\n",
        "| 커널초기화         | 르쿤(LeCun) 초기화                             |\n",
        "| 활성화 함수        | SELU                                           |\n",
        "| 정규화             | 필요 없음                                      |\n",
        "| 규제               | 경우에 따라 알파 드롭아웃|\n",
        "| 옵티마이저          | 모멘텀 최적화, RMSProp, Nadam 중 하나         |\n",
        "| 학습률 스케줄       | 1사이클                                        |"
      ],
      "metadata": {
        "id": "H5BxrrSCZjaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 희소모델인 경우\n",
        "+ $l_1$ 규제 사용 추천\n",
        "+ 매우 희소한 모델이 필요한 경우\n",
        "  + 텐서플로우의 모델최적화 툴킷(TF-MOT) 사용 가능"
      ],
      "metadata": {
        "id": "rtB7NZZdac9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 빠른 응답 모델인 경우\n",
        "+ 은닉층 수 줄이기\n",
        "+ 배치 정규화 층을 이전 층과 합치기\n",
        "+ LeakyReLU 또는 ReLU 사용\n",
        "+ 희소모델 사용"
      ],
      "metadata": {
        "id": "GhzOsc4LanxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 예측속도보다 정확도에 충실한 모델인 경우\n",
        "+ 몬테카를로 드롭아웃 사용 추천"
      ],
      "metadata": {
        "id": "KCCoV-Qda4z0"
      }
    }
  ]
}